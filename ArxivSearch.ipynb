{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdarshad1000/AudioWizard/blob/master/ArxivSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfgdkXmJocYJ"
      },
      "outputs": [],
      "source": [
        "!pip install -qU pinecone-client openai arxiv sentence_transformers kaggle tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "-qenle9ddAb7",
        "outputId": "78f0ca9a-446c-492d-b91c-8f80c3bd768d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0283348b-f600-4d0a-89a8-c1e2b78bf1c2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0283348b-f600-4d0a-89a8-c1e2b78bf1c2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIVfVKFMd23N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Move the uploaded kaggle.json file to the correct location\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "!cp kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29NxvpO1pjri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265a906d-e811-439e-9501-3572ea1f801f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import pinecone\n",
        "import kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m3t3xqhpDQy"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = 'mohdarshad'\n",
        "os.environ['KAGGLE_KEY'] = '40d4de066ed9cd77b90269abe6784589'\n",
        "openai.api_key = \"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\"\n",
        "OAI_MODEL = \"text-embedding-ada-002\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nQzH_YYoqY5",
        "outputId": "e1bdc19e-6569-4f27-ffd2-f66464cd5145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading arxiv.zip to /content\n",
            " 98% 1.16G/1.18G [00:12<00:00, 35.5MB/s]\n",
            "100% 1.18G/1.18G [00:12<00:00, 98.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d Cornell-University/arxiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoLK3Mvirfo1",
        "outputId": "b6d27153-0a5a-4ed4-9182-551b2b3302be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  arxiv.zip\n",
            "  inflating: arxiv-metadata-oai-snapshot.json  \n"
          ]
        }
      ],
      "source": [
        "!unzip arxiv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36odyY-uq8Cj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "data_path = './arxiv-metadata-oai-snapshot.json'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Paper:\n",
        "    def __init__(self, dict):\n",
        "        super().__init__()\n",
        "\n",
        "        self.id = dict[\"id\"]\n",
        "        self.categories = dict[\"categories\"].lower().split()\n",
        "\n",
        "        # remove line breaks and excess whitespace in titles\n",
        "        title = dict[\"title\"].replace(\"\\n\", \" \")\n",
        "        self.title = \" \".join(title.split())\n",
        "\n",
        "        # remove line breaks and excess whitespace in abstracts\n",
        "        abstract = dict[\"abstract\"].replace(\"\\n\", \" \")\n",
        "        self.abstract = \" \".join(abstract.split())\n",
        "\n",
        "        # retrieve month and year from first published date\n",
        "        self.month = dict[\"versions\"][0][\"created\"].split()[2]\n",
        "        self.year = int(dict[\"versions\"][0][\"created\"].split()[3])\n",
        "\n",
        "        # ensure first names are first, last names last, and no spaces\n",
        "        authors_parsed = dict[\"authors_parsed\"]\n",
        "        authors = [author[::-1][1:] for author in authors_parsed]\n",
        "        authors = [\" \".join(author).strip() for author in authors]\n",
        "        self.authors_string = \", \".join(authors)\n",
        "\n",
        "    def has_category(self, categories):\n",
        "        \"\"\"\n",
        "        Checks if the paper belongs to any of the categories in `categories`.\n",
        "\n",
        "        Args:\n",
        "            categories: List of category strings\n",
        "\n",
        "        Returns:\n",
        "            True if paper belongs to at least one category in `categories`,\n",
        "            False otherwise.\n",
        "        \"\"\"\n",
        "        for category in categories:\n",
        "            if category in self.categories:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    @property\n",
        "    def embedding_text(self):\n",
        "        \"\"\"\n",
        "        Text used for embedding the paper, combining title, authors, year, and\n",
        "        abstract.\n",
        "        \"\"\"\n",
        "        text = [\"Title: \" + self.title,\n",
        "                \"By: \" + self.authors_string,\n",
        "                \"From: \" + str(self.year),\n",
        "                \"Abstract: \" + self.abstract]\n",
        "        return \". \".join(text)\n",
        "\n",
        "    @property\n",
        "    def metadata(self):\n",
        "        return {\"title\": self.title,\n",
        "                \"authors\": self.authors_string,\n",
        "                \"abstract\": self.abstract,\n",
        "                \"year\": self.year,\n",
        "                \"month\": self.month}\n",
        "\n",
        "    @property\n",
        "    def has_valid_id(self):\n",
        "        invalid_id = self.id.isupper() or self.id.islower()\n",
        "        return not invalid_id"
      ],
      "metadata": {
        "id": "umtouCIaiCR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibu4wUHkvO4I"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path, categories, start_year):\n",
        "    \"\"\"\n",
        "    Returns a generator over the papers contained in `file_path`, belonging to\n",
        "    the categories in `categories`, and published in or after `start_year`.\n",
        "\n",
        "    Args:\n",
        "        file_path: The path to the JSON file containing the arXiv data\n",
        "        categories: A list of category strings\n",
        "        start_year: An integer specifying the earliest year to include\n",
        "\n",
        "    Returns:\n",
        "        A generator over the papers satisfying the criteria.\n",
        "    \"\"\"\n",
        "    json_file = open(file_path, \"r\", encoding=\"utf-8\")\n",
        "    papers = (Paper(json.loads(line)) for line in json_file)\n",
        "    papers = (paper for paper in papers\n",
        "              if paper.has_category(categories) and paper.has_valid_id)\n",
        "    return (paper for paper in papers if paper.year >= start_year)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "JSON_FILE_PATH = \"arxiv-metadata-oai-snapshot.json\"\n",
        "CATEGORIES = [\"cs.db\"]\n",
        "START_YEAR = 2012\n",
        "\n",
        "print(\"Loading data...\")\n",
        "papers = list(load_data(JSON_FILE_PATH, CATEGORIES, START_YEAR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1RJhgR7iEZ-",
        "outputId": "d0c71528-b9f4-45a0-81b9-fedac0761267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(papers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rvWRpgmxywi",
        "outputId": "7e5df35a-b345-4cbd-e5b7-67dac74a0945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6762"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "import getpass\n",
        "\n",
        "index_name = 'arxiv-search'\n",
        "\n",
        "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
        "pinecone.init(\n",
        "    api_key=getpass.getpass('PINECONE_API_KEY: '),\n",
        "    environment=getpass.getpass('ENVIRONEMENT: ')  # find next to api key in console\n",
        ")\n",
        "# check if 'openai' index already exists (only create index if not)\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(index_name, dimension=768)\n",
        "# connect to index\n",
        "index = pinecone.Index(index_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB2O3H21yNxp",
        "outputId": "16f33213-6525-46fd-a5d2-5cbfef5abf65"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PINECONE_API_KEY: ··········\n",
            "ENVIRONEMENT: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for paper in papers:\n",
        "  print(\"Id: \", paper.id)\n",
        "  print(\"title: \", paper.title)\n",
        "  print(\"authors: \", paper.authors_string)\n",
        "  print(\"abstract: \", paper.abstract)\n",
        "  print(\"category: \", paper.categories)\n",
        "  print(\"Year:\",  paper.year)\n",
        "  print(\"months: \", paper.month)\n",
        "  print('\\n\\n')\n",
        "  i += 1\n",
        "  if i >= 15:\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlsMrKlLyOnN",
        "outputId": "045e049b-9f4a-437b-9f2d-c9182946dc54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Id:  1201.1340\n",
            "title:  A Tiled-Table Convention for Compressing FITS Binary Tables\n",
            "authors:  William Pence, Rob Seaman, Richard L. White\n",
            "abstract:  This document describes a convention for compressing FITS binary tables that is modeled after the FITS tiled-image compression method (White et al. 2009) that has been in use for about a decade. The input table is first optionally subdivided into tiles, each containing an equal number of rows, then every column of data within each tile is compressed and stored as a variable-length array of bytes in the output FITS binary table. All the header keywords from the input table are copied to the header of the output table and remain uncompressed for efficient access. The output compressed table contains the same number and order of columns as in the input uncompressed binary table. There is one row in the output table corresponding to each tile of rows in the input table. In principle, each column of data can be compressed using a different algorithm that is optimized for the type of data within that column, however in the prototype implementation described here, the gzip algorithm is used to compress every column.\n",
            "category:  ['astro-ph.im', 'cs.db']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.1345\n",
            "title:  FITS Checksum Proposal\n",
            "authors:  Rob Seaman, William Pence, Arnold Rots\n",
            "abstract:  The checksum keywords described here provide an integrity check on the information contained in FITS HDUs. (Header and Data Units are the basic components of FITS files, consisting of header keyword records followed by optional associated data records). The CHECKSUM keyword is defined to have a value that forces the 32-bit 1's complement checksum accumulated over all the 2880-byte FITS logical records in the HDU to equal negative 0. (Note that 1's complement arithmetic has both positive and negative zero elements). Verifying that the accumulated checksum is still equal to -0 provides a fast and fairly reliable way to determine that the HDU has not been modified by subsequent data processing operations or corrupted while copying or storing the file on physical media.\n",
            "category:  ['astro-ph.im', 'cs.db']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.1829\n",
            "title:  FITS Foreign File Encapsulation Convention\n",
            "authors:  Nelson Zarate, Rob Seaman, Doug Tody\n",
            "abstract:  This document describes a FITS convention developed by the IRAF Group (D. Tody, R. Seaman, and N. Zarate) at the National Optical Astronomical Observatory (NOAO). This convention is implemented by the fgread/fgwrite tasks in the IRAF fitsutil package. It was first used in May 1999 to encapsulate preview PNG-format graphics files into FITS files in the NOAO High Performance Pipeline System. A FITS extension of type 'FOREIGN' provides a mechanism for storing an arbitrary file or tree of files in FITS, allowing it to be restored to disk at a later time.\n",
            "category:  ['astro-ph.im', 'cs.db']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.2564\n",
            "title:  Query-Subquery Nets\n",
            "authors:  Linh Anh Nguyen, Son Thanh Cao\n",
            "abstract:  We formulate query-subquery nets and use them to create the first framework for developing algorithms for evaluating queries to Horn knowledge bases with the properties that: the approach is goal-directed; each subquery is processed only once and each supplement tuple, if desired, is transferred only once; operations are done set-at-a-time; and any control strategy can be used. Our intention is to increase efficiency of query processing by eliminating redundant computation, increasing flexibility and reducing the number of accesses to the secondary storage. The framework forms a generic evaluation method called QSQN. To deal with function symbols, we use a term-depth bound for atoms and substitutions occurring in the computation and propose to use iterative deepening search which iteratively increases the term-depth bound. We prove soundness and completeness of our generic evaluation method and show that, when the term-depth bound is fixed, the method has PTIME data complexity. We also present how tail recursion elimination can be incorporated into our framework and propose two exemplary control strategies, one is to reduce the number of accesses to the secondary storage, while the other is depth-first search.\n",
            "category:  ['cs.db', 'cs.lo']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.2766\n",
            "title:  ART : Sub-Logarithmic Decentralized Range Query Processing with Probabilistic Guarantees\n",
            "authors:  Spyros Sioutas, Peter Triantafillou, George Papaloukopoulos, Evangelos Sakkopoulos, Kostas Tsichlas, Yannis Manolopoulos\n",
            "abstract:  We focus on range query processing on large-scale, typically distributed infrastructures, such as clouds of thousands of nodes of shared-datacenters, of p2p distributed overlays, etc. In such distributed environments, efficient range query processing is the key for managing the distributed data sets per se, and for monitoring the infrastructure's resources. We wish to develop an architecture that can support range queries in such large-scale decentralized environments and can scale in terms of the number of nodes as well as in terms of the data items stored. Of course, in the last few years there have been a number of solutions (mostly from researchers in the p2p domain) for designing such large-scale systems. However, these are inadequate for our purposes, since at the envisaged scales the classic logarithmic complexity (for point queries) is still too expensive while for range queries it is even more disappointing. In this paper we go one step further and achieve a sub-logarithmic complexity. We contribute the ART, which outperforms the most popular decentralized structures, including Chord (and some of its successors), BATON (and its successor) and Skip-Graphs. We contribute theoretical analysis, backed up by detailed experimental results, showing that the communication cost of query and update operations is $O(\\log_{b}^2 \\log N)$ hops, where the base $b$ is a double-exponentially power of two and $N$ is the total number of nodes. Moreover, ART is a fully dynamic and fault-tolerant structure, which supports the join/leave node operations in $O(\\log \\log N)$ expected w.h.p number of hops. Our experimental performance studies include a detailed performance comparison which showcases the improved performance, scalability, and robustness of ART.\n",
            "category:  ['cs.db']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.2925\n",
            "title:  Combining Heterogeneous Classifiers for Relational Databases\n",
            "authors:  Geetha Manjunatha, M Narasimha Murty, Dinkar Sitaram\n",
            "abstract:  Most enterprise data is distributed in multiple relational databases with expert-designed schema. Using traditional single-table machine learning techniques over such data not only incur a computational penalty for converting to a 'flat' form (mega-join), even the human-specified semantic information present in the relations is lost. In this paper, we present a practical, two-phase hierarchical meta-classification algorithm for relational databases with a semantic divide and conquer approach. We propose a recursive, prediction aggregation technique over heterogeneous classifiers applied on individual database tables. The proposed algorithm was evaluated on three diverse datasets, namely TPCH, PKDD and UCI benchmarks and showed considerable reduction in classification time without any loss of prediction accuracy.\n",
            "category:  ['cs.lg', 'cs.db']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.2969\n",
            "title:  SparseDTW: A Novel Approach to Speed up Dynamic Time Warping\n",
            "authors:  Ghazi Al-Naymat, Sanjay Chawla, Javid Taheri\n",
            "abstract:  We present a new space-efficient approach, (SparseDTW), to compute the Dynamic Time Warping (DTW) distance between two time series that always yields the optimal result. This is in contrast to other known approaches which typically sacrifice optimality to attain space efficiency. The main idea behind our approach is to dynamically exploit the existence of similarity and/or correlation between the time series. The more the similarity between the time series the less space required to compute the DTW between them. To the best of our knowledge, all other techniques to speedup DTW, impose apriori constraints and do not exploit similarity characteristics that may be present in the data. We conduct experiments and demonstrate that SparseDTW outperforms previous approaches.\n",
            "category:  ['cs.db', 'cs.ds']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.3458\n",
            "title:  Detecting Priming News Events\n",
            "authors:  Di Wu, Yiping Ke, Jeffrey Xu Yu, Zheng Liu\n",
            "abstract:  We study a problem of detecting priming events based on a time series index and an evolving document stream. We define a priming event as an event which triggers abnormal movements of the time series index, i.e., the Iraq war with respect to the president approval index of President Bush. Existing solutions either focus on organizing coherent keywords from a document stream into events or identifying correlated movements between keyword frequency trajectories and the time series index. In this paper, we tackle the problem in two major steps. (1) We identify the elements that form a priming event. The element identified is called influential topic which consists of a set of coherent keywords. And we extract them by looking at the correlation between keyword trajectories and the interested time series index at a global level. (2) We extract priming events by detecting and organizing the bursty influential topics at a micro level. We evaluate our algorithms on a real-world dataset and the result confirms that our method is able to discover the priming events effectively.\n",
            "category:  ['cs.db']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.4479\n",
            "title:  Distributed Data Storage in Large-Scale Sensor Networks Based on LT Codes\n",
            "authors:  Saber Jafarizadeh, Abbas Jamalipour\n",
            "abstract:  This paper proposes an algorithm for increasing data persistency in large-scale sensor networks. In the scenario considered here, k out of n nodes sense the phenomenon and produced ? information packets. Due to usually hazardous environment and limited resources, e.g. energy, sensors in the network are vulnerable. Also due to the large size of the network, gathering information from a few central hopes is not feasible. Flooding is not a desired option either due to limited memory of each node. Therefore the best approach to increase data persistency is propagating data throughout the network by random walks. The algorithm proposed here is based on distributed LT (Luby Transform) codes and it benefits from the low complexity of encoding and decoding of LT codes. In previous algorithms the essential global information (e.g., n and k) are estimated based on graph statistics, which requires excessive transmissions. In our proposed algorithm, these values are obtained without additional transmissions. Also the mixing time of random walk is enhanced by proposing a new scheme for generating the probabilistic forwarding table of random walk. The proposed method uses only local information and it is scalable to any network topology. By simulations the improved performance of developed algorithm compared to previous ones has been verified.\n",
            "category:  ['cs.it', 'cs.db', 'math.it']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.6112\n",
            "title:  An Efficient Method for Mining Event-Related Potential Patterns\n",
            "authors:  Seyed Aliakbar Mousavi, Muhammad Rafie Hj Arshad, Hasimah Hj Mohamed, Saleh Ali Alomari\n",
            "abstract:  In the present paper, we propose a Neuroelectromagnetic Ontology Framework (NOF) for mining Event-related Potentials (ERP) patterns as well as the process. The aim for this research is to develop an infrastructure for mining, analysis and sharing the ERP domain ontologies. The outcome of this research is a Neuroelectromagnetic knowledge-based system. The framework has 5 stages: 1) Data pre-processing and preparation; 2) Data mining application; 3) Rule Comparison and Evaluation; 4) Association rules Post-processing 5) Domain Ontologies. In 5th stage a new set of hidden rules can be discovered base on comparing association rules by domain ontologies and expert rules.\n",
            "category:  ['cs.db']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.6402\n",
            "title:  A Note on Disk Drag Dynamics\n",
            "authors:  Neil J. Gunther\n",
            "abstract:  The electrical power consumed by typical magnetic hard disk drives (HDD) not only increases linearly with the number of spindles but, more significantly, it increases as very fast power-laws of speed (RPM) and diameter. Since the theoretical basis for this relationship is neither well-known nor readily accessible in the literature, we show how these exponents arise from aerodynamic disk drag and discuss their import for green storage capacity planning.\n",
            "category:  ['cs.pf', 'cs.db', 'physics.class-ph']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.6563\n",
            "title:  Relation Strength-Aware Clustering of Heterogeneous Information Networks with Incomplete Attributes\n",
            "authors:  Yizhou Sun, Charu C. Aggarwal, Jiawei Han\n",
            "abstract:  With the rapid development of online social media, online shopping sites and cyber-physical systems, heterogeneous information networks have become increasingly popular and content-rich over time. In many cases, such networks contain multiple types of objects and links, as well as different kinds of attributes. The clustering of these objects can provide useful insights in many applications. However, the clustering of such networks can be challenging since (a) the attribute values of objects are often incomplete, which implies that an object may carry only partial attributes or even no attributes to correctly label itself; and (b) the links of different types may carry different kinds of semantic meanings, and it is a difficult task to determine the nature of their relative importance in helping the clustering for a given purpose. In this paper, we address these challenges by proposing a model-based clustering algorithm. We design a probabilistic model which clusters the objects of different types into a common hidden space, by using a user-specified set of attributes, as well as the links from different relations. The strengths of different types of links are automatically learned, and are determined by the given purpose of clustering. An iterative algorithm is designed for solving the clustering problem, in which the strengths of different types of links and the quality of clustering results mutually enhance each other. Our experimental results on real and synthetic data sets demonstrate the effectiveness and efficiency of the algorithm.\n",
            "category:  ['cs.db']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.6564\n",
            "title:  Shortest Path and Distance Queries on Road Networks: An Experimental Evaluation\n",
            "authors:  Lingkun Wu, Xiaokui Xiao, Dingxiong Deng, Gao Cong, Andy Diwen Zhu, Shuigeng Zhou\n",
            "abstract:  Computing the shortest path between two given locations in a road network is an important problem that finds applications in various map services and commercial navigation products. The state-of-the-art solutions for the problem can be divided into two categories: spatial-coherence-based methods and vertex-importance-based approaches. The two categories of techniques, however, have not been compared systematically under the same experimental framework, as they were developed from two independent lines of research that do not refer to each other. This renders it difficult for a practitioner to decide which technique should be adopted for a specific application. Furthermore, the experimental evaluation of the existing techniques, as presented in previous work, falls short in several aspects. Some methods were tested only on small road networks with up to one hundred thousand vertices; some approaches were evaluated using distance queries (instead of shortest path queries), namely, queries that ask only for the length of the shortest path; a state-of-the-art technique was examined based on a faulty implementation that led to incorrect query results. To address the above issues, this paper presents a comprehensive comparison of the most advanced spatial-coherence-based and vertex-importance-based approaches. Using a variety of real road networks with up to twenty million vertices, we evaluated each technique in terms of its preprocessing time, space consumption, and query efficiency (for both shortest path and distance queries). Our experimental results reveal the characteristics of different techniques, based on which we provide guidelines on selecting appropriate methods for various scenarios.\n",
            "category:  ['cs.db']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.6565\n",
            "title:  The Filter-Placement Problem and its Application to Minimizing Information Multiplicity\n",
            "authors:  Dóra Erdös, Vatche Ishakian, Andrei Lapets, Evimaria Terzi, Azer Bestavros\n",
            "abstract:  In many information networks, data items -- such as updates in social networks, news flowing through interconnected RSS feeds and blogs, measurements in sensor networks, route updates in ad-hoc networks -- propagate in an uncoordinated manner: nodes often relay information they receive to neighbors, independent of whether or not these neighbors received the same information from other sources. This uncoordinated data dissemination may result in significant, yet unnecessary communication and processing overheads, ultimately reducing the utility of information networks. To alleviate the negative impacts of this information multiplicity phenomenon, we propose that a subset of nodes (selected at key positions in the network) carry out additional information filtering functionality. Thus, nodes are responsible for the removal (or significant reduction) of the redundant data items relayed through them. We refer to such nodes as filters. We formally define the Filter Placement problem as a combinatorial optimization problem, and study its computational complexity for different types of graphs. We also present polynomial-time approximation algorithms and scalable heuristics for the problem. Our experimental results, which we obtained through extensive simulations on synthetic and real-world information flow networks, suggest that in many settings a relatively small number of filters are fairly effective in removing a large fraction of redundant information.\n",
            "category:  ['cs.db']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n",
            "Id:  1201.6566\n",
            "title:  Fast and Exact Top-k Search for Random Walk with Restart\n",
            "authors:  Yasuhiro Fujiwara, Makoto Nakatsuji, Makoto Onizuka, Masaru Kitsuregawa\n",
            "abstract:  Graphs are fundamental data structures and have been employed for centuries to model real-world systems and phenomena. Random walk with restart (RWR) provides a good proximity score between two nodes in a graph, and it has been successfully used in many applications such as automatic image captioning, recommender systems, and link prediction. The goal of this work is to find nodes that have top-k highest proximities for a given node. Previous approaches to this problem find nodes efficiently at the expense of exactness. The main motivation of this paper is to answer, in the affirmative, the question, `Is it possible to improve the search time without sacrificing the exactness?'. Our solution, {it K-dash}, is based on two ideas: (1) It computes the proximity of a selected node efficiently by sparse matrices, and (2) It skips unnecessary proximity computations when searching for the top-k nodes. Theoretical analyses show that K-dash guarantees result exactness. We perform comprehensive experiments to verify the efficiency of K-dash. The results show that K-dash can find top-k nodes significantly faster than the previous approaches while it guarantees exactness.\n",
            "category:  ['cs.db']\n",
            "Year: 2012\n",
            "months:  Jan\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "ST_MODEL = SentenceTransformer('sentence-transformers/paraphrase-mpnet-base-v2')"
      ],
      "metadata": {
        "id": "BFFCN8xhyubq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = ST_MODEL.encode(\"HELLO\")\n",
        "len(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_42BhpISyz44",
        "outputId": "31d5771d-b5cb-4b42-cc45-0edb337a155f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(texts, model=\"sentence-transformers/paraphrase-mpnet-base-v2\"):\n",
        "    \"\"\"\n",
        "    Returns a list of embeddings for each string in `texts` using the OpenAI\n",
        "    embedding model specified in `model`.\n",
        "\n",
        "    Args:\n",
        "        texts: A list of strings to embed\n",
        "        model: The name of the OpenAI embedding model to use\n",
        "\n",
        "    Returns:\n",
        "        A list of embeddings.\n",
        "    \"\"\"\n",
        "    embed_data = ST_MODEL.encode(texts)\n",
        "    return embed_data\n"
      ],
      "metadata": {
        "id": "gKax0vIL0Nq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = get_embeddings(\"HELLO\").tolist()"
      ],
      "metadata": {
        "id": "JIAVSApx0Wcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_and_upsert(papers, index_name, model, batch_size=100):\n",
        "    \"\"\"\n",
        "    Embeds the embedding text of each paper in `papers` using the embedding\n",
        "    model specified in `model`. The embeddings are then upserted to the Pinecone\n",
        "    index with name `index_name` in batches of size `batch_size`.\n",
        "\n",
        "    Args:\n",
        "        papers: The list of papers for which to embed their embedding text\n",
        "        index_name: The name of the index in which the embeddings will be upserted\n",
        "        model: The name of the OpenAI embedding model to use\n",
        "        batch_size: The batch size to use when upserting embeddings to Pinecone\n",
        "    \"\"\"\n",
        "    with pinecone.Index(index_name, pool_threads=5) as index:\n",
        "        for i in tqdm(range(0, len(papers), batch_size)):\n",
        "            batch = papers[i:i+batch_size]\n",
        "            texts = [paper.embedding_text for paper in batch]\n",
        "            embed_data = get_embeddings(texts, model).tolist()\n",
        "\n",
        "            pc_data = [(p.id, e, p.metadata)\n",
        "                       for p, e in zip(batch, embed_data)]\n",
        "            index.upsert(pc_data)"
      ],
      "metadata": {
        "id": "DcRpxXFP0uQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_and_upsert(papers, index_name, ST_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a985215aec734965b921c9f09b751fdb",
            "4cdeb82315834cb0a3706282aceafb09",
            "ca5cf268f57f44f194682c030396674c",
            "8869cb03513a4e0d9a629061295e2fcc",
            "b6180b423e4842369d7de4f808e1c81b",
            "a89b019ded6f4c2790302203c9af1337",
            "aee74aa1ddd34dce8ddfd3adfc096316",
            "a9764a8c89f14e9cbaa9cbf3c55b18eb",
            "31bdbdeb3e9544d78fb4c57f262d7d61",
            "71774497dd1e4a76bb5c4374ba902323",
            "8b1e4b96a7cf4f27a0eedfcd02d8c920"
          ]
        },
        "id": "PNfE1x8J1Oj-",
        "outputId": "28ebd374-82e6-4696-d900-161fc0d8a0cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/68 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a985215aec734965b921c9f09b751fdb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xq = \"Comparison of non-relational vs relational database\"\n",
        "embed = get_embeddings(xq).tolist()"
      ],
      "metadata": {
        "id": "unM9DJon1kr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = index.query([embed], top_k=5, include_metadata=True)\n"
      ],
      "metadata": {
        "id": "kYTjJogP6yIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for match in res['matches']:\n",
        "    print(f\"{match['score']:.2f}: {match['metadata']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiIl2uEN7fct",
        "outputId": "2b41ca1e-994a-41b5-deb6-9e2fb27aa97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.61: {'abstract': 'This paper is an extended version of a report from a student-developed study to compare Microsoft SQL Server and PostgreSQL, two widely-used enterprise-class relational database management systems (RDBMSs). The study followed an introductory undergraduate course in relational systems and was designed to help gain practical understanding of specific DBMSs. During this study, we implemented three non-trivial schemas in each system, identified 26 common database design, development, and administration activities while implementing the schemas, and compared the support each system offers to carry out the identified activities. Where relevant, we also compared each system against the SQL standard. In this report, we present a summary of the similarities and differences we found between the two systems, and we provide a quantitative measure ranking both systems\\' implementations of the 26 activities. We also briefly discuss the \"technical suitability\" of PostgreSQL to enterprise applications. Although this report is not comprehensive and is too general to comment on the suitability of either system to a specific enterprise application, it can nevertheless provide an initial set of considerations and criteria to choose a system for most enterprise applications.', 'authors': 'Andrew Figueroa, Steven Rollo, Sean Murthy', 'month': 'Oct', 'title': 'A Brief Comparison of Two Enterprise-Class RDBMSs', 'year': 2017.0}\n",
            "0.61: {'abstract': \"The relational data model requires a theory of relations in which tuples are not only many-sorted, but can also have indexes that are not necessarily numerical. In this paper we develop such a theory and define operations on relations that are adequate for database use. The operations are similar to those of Codd's relational algebra, but differ in being based on a mathematically adequate theory of relations. The semantics of predicate calculus, being oriented toward the concept of satisfiability, is not suitable for relational databases. We develop an alternative semantics that assigns relations as meaning to formulas with free variables. This semantics makes the classical predicate calculus suitable as a query language for relational databases.\", 'authors': 'Philip Kelly, M. H. van Emden', 'month': 'Feb', 'title': 'Relational Semantics for Databases and Predicate Calculus', 'year': 2012.0}\n",
            "0.58: {'abstract': 'Despite great advances in the area of Semantic Web, industry rather seldom adopts Semantic Web technologies and their storage and query concepts. Instead, relational databases (RDB) are often deployed to store business-critical data, which are accessed via REST interfaces. Yet, some enterprises would greatly benefit from Semantic Web related datasets which are usually represented with the Resource Description Framework (RDF). To bridge this technology gap, we propose a fully automatic approach that generates suitable RDB models with REST APIs to access them. In our evaluation, generated databases from different RDF datasets are examined and compared. Our findings show that the databases sufficiently reflect their counterparts while the API is able to reproduce rather simple SPARQL queries. Potentials for improvements are identified, for example, the reduction of data redundancies in generated databases.', 'authors': 'Markus Schröder, Michael Schulze, Christian Jilek, Andreas Dengel', 'month': 'Nov', 'title': 'Bridging the Technology Gap Between Industry and Semantic Web: Generating Databases and Server Code From RDF', 'year': 2020.0}\n",
            "0.57: {'abstract': \"Data analysis often involves comparing subsets of data across many dimensions for finding unusual trends and patterns. While the comparison between subsets of data can be expressed using SQL, they tend to be complex to write, and suffer from poor performance over large and high-dimensional datasets. In this paper, we propose a new logical operator COMPARE for relational databases that concisely captures the enumeration and comparison between subsets of data and greatly simplifies the expressing of a large class of comparative queries. We extend the database engine with optimization techniques that exploit the semantics of COMPARE to significantly improve the performance of such queries. We have implemented these extensions inside Microsoft SQL Server, a commercial DBMS engine. Our extensive evaluation on synthetic and real-world datasets shows that COMPARE results in a significant speedup over existing approaches, including physical plans generated by today's database systems, user-defined function (UDF), as well as middleware solutions that compare subsets outside the databases.\", 'authors': 'Tarique Siddiqui, Surajit Chaudhuri, Vivek Narasayya', 'month': 'Jul', 'title': 'COMPARE: Accelerating Groupwise Comparison in Relational Databases for Data Analytics', 'year': 2021.0}\n",
            "0.57: {'abstract': 'Relational databases play an important role in this Big Data era. However, it is challenging for non-experts to fully unleash the analytical power of relational databases, since they are not familiar with database languages such as SQL. Many techniques have been proposed to automatically generate SQL from natural language, but they suffer from two issues: (1) they still make many mistakes, particularly for complex queries, and (2) they do not provide a flexible way for non-expert users to validate and refine the incorrect queries. To address these issues, we introduce a new interaction mechanism that allows users directly edit a step-by-step explanation of an incorrect SQL to fix SQL errors. Experiments on the Spider benchmark show that our approach outperforms three SOTA approaches by at least 31.6% in terms of execution accuracy. A user study with 24 participants further shows that our approach helped users solve significantly more SQL tasks with less time and higher confidence, demonstrating its potential to expand access to databases, particularly for non-experts.', 'authors': 'Yuan Tian, Zheng Zhang, Zheng Ning, Toby Jia-Jun Li, Jonathan K. Kummerfeld, Tianyi Zhang', 'month': 'May', 'title': 'Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations', 'year': 2023.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EMBEDDING USING OPENAI\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def get_embeddings_OAI(texts, model=\"text-embedding-ada-002\"):\n",
        "    \"\"\"\n",
        "    Returns a list of embeddings for each string in `texts` using the OpenAI\n",
        "    embedding model specified in `model`.\n",
        "\n",
        "    Args:\n",
        "        texts: A list of strings to embed\n",
        "        model: The name of the OpenAI embedding model to use\n",
        "\n",
        "    Returns:\n",
        "        A list of embeddings.\n",
        "    \"\"\"\n",
        "    embed_data = openai.Embedding.create(input=texts, model=model)\n",
        "    return embed_data[\"data\"]\n",
        "\n",
        "\n",
        "def embed_and_upsert_OAI(papers, index_name, model, batch_size=100):\n",
        "  \"\"\"\n",
        "    Embeds the embedding text of each paper in `papers` using the embedding\n",
        "    model specified in `model`. The embeddings are then upserted to the Pinecone\n",
        "    index with name `index_name` in batches of size `batch_size`.\n",
        "\n",
        "    Args:\n",
        "        papers: The list of papers for which to embed their embedding text\n",
        "        index_name: The name of the index in which the embeddings will be upserted\n",
        "        model: The name of the OpenAI embedding model to use\n",
        "        batch_size: The batch size to use when upserting embeddings to Pinecone\n",
        "    \"\"\"\n",
        "  with pinecone.Index(index_name, pool_threads=5) as index:\n",
        "      for i in tqdm(range(0, len(papers), batch_size)):\n",
        "          batch = papers[i:i+batch_size]\n",
        "          texts = [paper.embedding_text for paper in batch]\n",
        "          embed_data = get_embeddings_OAI(texts, model)\n",
        "\n",
        "          pc_data = [(p.id, e[\"embedding\"], p.metadata)\n",
        "                      for p, e in zip(batch, embed_data)]\n",
        "          index.upsert(pc_data)"
      ],
      "metadata": {
        "id": "9tFohWx28aHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_and_upsert_OAI(papers, index_name, OAI_MODEL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0d9250f968634a6da33fc73d28747be4",
            "6304fda6329e4b9a8798c53bd00ca9c5",
            "0d76b4741c1643618ba9f0c37dbb073f",
            "a30b9b0c75f342fb85ce090ce3426fef",
            "67c9682e6b5c455199a8d18670d998e4",
            "7638a79cc63f4c1c8df5cd90e0ecc91a",
            "4785676edc5b40a391e922a8c1c28043",
            "a07db1f589b9433f984f5d459f047d65",
            "a754ab19787947a6923325f490135668",
            "340f0b03d9d1473dbca115883c4a1cc0",
            "c22b93678ddf42eeb1ef1e0981334a05"
          ]
        },
        "id": "jbARhbK9-dE-",
        "outputId": "22fab6bf-c3b9-44f2-d1e7-c868315ed819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/68 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d9250f968634a6da33fc73d28747be4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xr = \"Comparison of non-relational vs relational database\"\n",
        "embed_xr = openai.Embedding.create(input=xr, engine=OAI_MODEL)['data'][0]['embedding']"
      ],
      "metadata": {
        "id": "MVpSC1Fk-fti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = index.query([embed_xr], top_k=5, include_metadata=True)\n",
        "\n",
        "for match in res['matches']:\n",
        "    print(f\"{match['score']:.2f}: {match}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8btJE9LBlKR",
        "outputId": "6437dc28-927b-4c8b-ab2e-aef39f49b404"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.85: {'id': '1710.08023',\n",
            " 'metadata': {'abstract': 'This paper is an extended version of a report from '\n",
            "                          'a student-developed study to compare Microsoft SQL '\n",
            "                          'Server and PostgreSQL, two widely-used '\n",
            "                          'enterprise-class relational database management '\n",
            "                          'systems (RDBMSs). The study followed an '\n",
            "                          'introductory undergraduate course in relational '\n",
            "                          'systems and was designed to help gain practical '\n",
            "                          'understanding of specific DBMSs. During this study, '\n",
            "                          'we implemented three non-trivial schemas in each '\n",
            "                          'system, identified 26 common database design, '\n",
            "                          'development, and administration activities while '\n",
            "                          'implementing the schemas, and compared the support '\n",
            "                          'each system offers to carry out the identified '\n",
            "                          'activities. Where relevant, we also compared each '\n",
            "                          'system against the SQL standard. In this report, we '\n",
            "                          'present a summary of the similarities and '\n",
            "                          'differences we found between the two systems, and '\n",
            "                          'we provide a quantitative measure ranking both '\n",
            "                          \"systems' implementations of the 26 activities. We \"\n",
            "                          'also briefly discuss the \"technical suitability\" of '\n",
            "                          'PostgreSQL to enterprise applications. Although '\n",
            "                          'this report is not comprehensive and is too general '\n",
            "                          'to comment on the suitability of either system to a '\n",
            "                          'specific enterprise application, it can '\n",
            "                          'nevertheless provide an initial set of '\n",
            "                          'considerations and criteria to choose a system for '\n",
            "                          'most enterprise applications.',\n",
            "              'authors': 'Andrew Figueroa, Steven Rollo, Sean Murthy',\n",
            "              'month': 'Oct',\n",
            "              'title': 'A Brief Comparison of Two Enterprise-Class RDBMSs',\n",
            "              'year': 2017.0},\n",
            " 'score': 0.854828596,\n",
            " 'values': []}\n",
            "0.85: {'id': '2107.11967',\n",
            " 'metadata': {'abstract': 'Data analysis often involves comparing subsets of '\n",
            "                          'data across many dimensions for finding unusual '\n",
            "                          'trends and patterns. While the comparison between '\n",
            "                          'subsets of data can be expressed using SQL, they '\n",
            "                          'tend to be complex to write, and suffer from poor '\n",
            "                          'performance over large and high-dimensional '\n",
            "                          'datasets. In this paper, we propose a new logical '\n",
            "                          'operator COMPARE for relational databases that '\n",
            "                          'concisely captures the enumeration and comparison '\n",
            "                          'between subsets of data and greatly simplifies the '\n",
            "                          'expressing of a large class of comparative queries. '\n",
            "                          'We extend the database engine with optimization '\n",
            "                          'techniques that exploit the semantics of COMPARE to '\n",
            "                          'significantly improve the performance of such '\n",
            "                          'queries. We have implemented these extensions '\n",
            "                          'inside Microsoft SQL Server, a commercial DBMS '\n",
            "                          'engine. Our extensive evaluation on synthetic and '\n",
            "                          'real-world datasets shows that COMPARE results in a '\n",
            "                          'significant speedup over existing approaches, '\n",
            "                          \"including physical plans generated by today's \"\n",
            "                          'database systems, user-defined function (UDF), as '\n",
            "                          'well as middleware solutions that compare subsets '\n",
            "                          'outside the databases.',\n",
            "              'authors': 'Tarique Siddiqui, Surajit Chaudhuri, Vivek Narasayya',\n",
            "              'month': 'Jul',\n",
            "              'title': 'COMPARE: Accelerating Groupwise Comparison in '\n",
            "                       'Relational Databases for Data Analytics',\n",
            "              'year': 2021.0},\n",
            " 'score': 0.847807,\n",
            " 'values': []}\n",
            "0.84: {'id': '2301.00847',\n",
            " 'metadata': {'abstract': 'Databases are considered to be integral part of '\n",
            "                          'modern information systems. Almost every web or '\n",
            "                          'mobile application uses some kind of database. '\n",
            "                          'Database management systems are considered to be a '\n",
            "                          'crucial element from both business and '\n",
            "                          'technological standpoint. This paper divides '\n",
            "                          'different types of database management systems into '\n",
            "                          'two main categories (relational and non-relational) '\n",
            "                          'and several sub categories. Ranking of various sub '\n",
            "                          'categories for the month of July, 2021 are '\n",
            "                          'presented in the form of popularity score '\n",
            "                          'calculated and managed by DB-Engines. Popularity '\n",
            "                          'trend for each category is also presented to look '\n",
            "                          'at the change in popularity since 2013. Complete '\n",
            "                          'ranking and trend of top 20 systems has shown that '\n",
            "                          'relational models are still most popular systems '\n",
            "                          'with Oracle and MySQL being two most popular '\n",
            "                          'systems. However, recent trends have shown DBMSs '\n",
            "                          'like Time Series and Document Store getting more '\n",
            "                          'and more popular with their wide use in IOT '\n",
            "                          'technology and BigData, respectively.',\n",
            "              'authors': 'Aleem Akhtar',\n",
            "              'month': 'Jan',\n",
            "              'title': 'Popularity Ranking of Database Management Systems',\n",
            "              'year': 2023.0},\n",
            " 'score': 0.843759179,\n",
            " 'values': []}\n",
            "0.84: {'id': '1701.00072',\n",
            " 'metadata': {'abstract': 'Process-Aware Information System (PAIS) are IT '\n",
            "                          'systems that manages, supports business processes '\n",
            "                          'and generate large event logs from execution of '\n",
            "                          'business processes. An event log is represented as '\n",
            "                          'a tuple of the form CaseID, TimeStamp, Activity and '\n",
            "                          'Actor. Process Mining is an emerging area of '\n",
            "                          'research that deals with the study and analysis of '\n",
            "                          'business processes based on event logs. Process '\n",
            "                          'Mining aims at analyzing event logs and discover '\n",
            "                          'business process models, enhance them or check for '\n",
            "                          'conformance with an a priori model. The large '\n",
            "                          'volume of event logs generated are stored in '\n",
            "                          'databases. Relational databases perform well for '\n",
            "                          'certain class of applications. However, there are '\n",
            "                          'certain class of applications for which relational '\n",
            "                          'databases are not able to scale. A number of NoSQL '\n",
            "                          'databases have emerged to encounter the challenges '\n",
            "                          'of scalability. Discovering social network from '\n",
            "                          'event logs is one of the most challenging and '\n",
            "                          'important Process Mining task. Similar-Task and '\n",
            "                          'Sub-Contract algorithms are some of the most widely '\n",
            "                          'used Organizational Mining techniques. Our '\n",
            "                          'objective is to investigate which of the databases '\n",
            "                          '(Relational or Graph) perform better for '\n",
            "                          'Organizational Mining under Process Mining. An '\n",
            "                          'intersection of Process Mining and Graph Databases '\n",
            "                          'can be accomplished by modelling these '\n",
            "                          'Organizational Mining metrics with graph databases. '\n",
            "                          'We implement Similar-Task and Sub-Contract '\n",
            "                          'algorithms on relational and NoSQL (graph-oriented) '\n",
            "                          'databases using only query language constructs. We '\n",
            "                          'conduct empirical analysis on a large real world '\n",
            "                          'data set to compare the performance of row-oriented '\n",
            "                          'database and NoSQL graph-oriented database. We '\n",
            "                          'benchmark performance factors like query execution '\n",
            "                          'time, CPU usage and disk/memory space usage for '\n",
            "                          'NoSQL graph-oriented database against row-oriented '\n",
            "                          'database.',\n",
            "              'authors': 'Jeevan Joishi, Ashish Sureka',\n",
            "              'month': 'Dec',\n",
            "              'title': 'Graph or Relational Databases: A Speed Comparison for '\n",
            "                       'Process Mining Algorithm',\n",
            "              'year': 2016.0},\n",
            " 'score': 0.842494726,\n",
            " 'values': []}\n",
            "0.84: {'id': '1809.03822',\n",
            " 'metadata': {'abstract': 'A significant category of NoSQL approaches is known '\n",
            "                          'as graph da-tabases. They are usually represented '\n",
            "                          'by one property graph. We introduce a functional '\n",
            "                          'approach to modelling relations and property '\n",
            "                          'graphs. Single-valued and multivalued functions '\n",
            "                          'will be sufficient in this case. Then, a typed '\n",
            "                          '{\\\\lambda}-calculus, i.e., the language of lambda '\n",
            "                          'terms, will be used as a data manipulation '\n",
            "                          'lan-guage. Some integration options at the query '\n",
            "                          'language level are discussed.',\n",
            "              'authors': 'Jaroslav Pokorny',\n",
            "              'month': 'Sep',\n",
            "              'title': 'Integration of Relational and Graph Databases '\n",
            "                       'Functionally',\n",
            "              'year': 2018.0},\n",
            " 'score': 0.840696275,\n",
            " 'values': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-P4KQKPIBuj8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNvp9i7Tnm0IYhc26+SQ/nR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a985215aec734965b921c9f09b751fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cdeb82315834cb0a3706282aceafb09",
              "IPY_MODEL_ca5cf268f57f44f194682c030396674c",
              "IPY_MODEL_8869cb03513a4e0d9a629061295e2fcc"
            ],
            "layout": "IPY_MODEL_b6180b423e4842369d7de4f808e1c81b"
          }
        },
        "4cdeb82315834cb0a3706282aceafb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a89b019ded6f4c2790302203c9af1337",
            "placeholder": "​",
            "style": "IPY_MODEL_aee74aa1ddd34dce8ddfd3adfc096316",
            "value": "100%"
          }
        },
        "ca5cf268f57f44f194682c030396674c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9764a8c89f14e9cbaa9cbf3c55b18eb",
            "max": 68,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31bdbdeb3e9544d78fb4c57f262d7d61",
            "value": 68
          }
        },
        "8869cb03513a4e0d9a629061295e2fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71774497dd1e4a76bb5c4374ba902323",
            "placeholder": "​",
            "style": "IPY_MODEL_8b1e4b96a7cf4f27a0eedfcd02d8c920",
            "value": " 68/68 [03:15&lt;00:00,  2.65s/it]"
          }
        },
        "b6180b423e4842369d7de4f808e1c81b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a89b019ded6f4c2790302203c9af1337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aee74aa1ddd34dce8ddfd3adfc096316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9764a8c89f14e9cbaa9cbf3c55b18eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31bdbdeb3e9544d78fb4c57f262d7d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71774497dd1e4a76bb5c4374ba902323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b1e4b96a7cf4f27a0eedfcd02d8c920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d9250f968634a6da33fc73d28747be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6304fda6329e4b9a8798c53bd00ca9c5",
              "IPY_MODEL_0d76b4741c1643618ba9f0c37dbb073f",
              "IPY_MODEL_a30b9b0c75f342fb85ce090ce3426fef"
            ],
            "layout": "IPY_MODEL_67c9682e6b5c455199a8d18670d998e4"
          }
        },
        "6304fda6329e4b9a8798c53bd00ca9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7638a79cc63f4c1c8df5cd90e0ecc91a",
            "placeholder": "​",
            "style": "IPY_MODEL_4785676edc5b40a391e922a8c1c28043",
            "value": "100%"
          }
        },
        "0d76b4741c1643618ba9f0c37dbb073f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a07db1f589b9433f984f5d459f047d65",
            "max": 68,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a754ab19787947a6923325f490135668",
            "value": 68
          }
        },
        "a30b9b0c75f342fb85ce090ce3426fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_340f0b03d9d1473dbca115883c4a1cc0",
            "placeholder": "​",
            "style": "IPY_MODEL_c22b93678ddf42eeb1ef1e0981334a05",
            "value": " 68/68 [01:37&lt;00:00,  1.26s/it]"
          }
        },
        "67c9682e6b5c455199a8d18670d998e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7638a79cc63f4c1c8df5cd90e0ecc91a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4785676edc5b40a391e922a8c1c28043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a07db1f589b9433f984f5d459f047d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a754ab19787947a6923325f490135668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "340f0b03d9d1473dbca115883c4a1cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c22b93678ddf42eeb1ef1e0981334a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}